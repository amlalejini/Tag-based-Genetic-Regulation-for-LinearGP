[["index.html", "Analyses for Tag-based Genetic Regulation for Genetic Programming Chapter 1 Test", " Analyses for Tag-based Genetic Regulation for Genetic Programming Alexander Lalejini 2020-12-08 Chapter 1 Test "],["signalgp-digital-organisms.html", "Chapter 2 SignalGP Digital Organisms 2.1 Memory model 2.2 Mutation operators 2.3 Instruction Set 2.4 References", " Chapter 2 SignalGP Digital Organisms Here, we give more details on the setup of the SignalGP digital organisms used in the diagnostic experiments. For a broad overview of SignalGP, see (Lalejini and Ofria, 2018). For specific parameter choices, see experiment-specific configuration descriptions (TODO - link here). For DISHTINY SignalGP details, see DISHTINY docs. Navigation Memory model Mutation operators Instruction Set Default Instructions Global memory access instructions Regulation instructions Task-specific instructions References 2.1 Memory model SignalGP digital organisms have four types of memory buffers with which to carry out computations: Working (register) memory Call-local (* thread-local) memory. Memory used by the majority of computation instructions. Input memory Call-local (&amp; thread-local) memory. Read-only. This memory is used to specify function call arguments. When a function is called on a thread (i.e., a call instruction is executed), the caller’s working memory is copied into the input memory of the new call-state, which is created on top of the thread’s call stack. Programs must execute explicit instructions to read from the input memory buffer (into the working memory buffer). Output memory Call-local (&amp; thread-local) memory. Write-only. This memory is used to specify the return values of a function call. When a function returns to the previous call-state (i.e., the one just below it on the thread’s call stack), positions that were set in the output buffer are returned to the caller’s working memory buffer. Programs must execute explicit instructions to write to the output memory buffer (from the working memory buffer). Global memory This memory buffer is shared by all executing threads. Threads must use explicit instructions (GlobalToWorking or WorkingToGlobal) to access it. These are described in more detail in (Lalejini and Ofria, 2018). Memory buffers are implemented as integer =&gt; double maps. 2.2 Mutation operators Single-instruction insertions Applied per instruction Single-instruction deletions Applied per instruction Single-instruction substitutions Applied per instruction Single-argument substitutions Applied per argument Slip mutations (Lalejini et al., 2017) Applied at a per-function rate. Pick two random positions in function’s instructions sequence: A and B If A &lt; B: duplicate sequence from A to B If A &gt; B: delete sequence from A to B Single-function duplications Applied per-function Single-function deletions Applied per-function Tag bit flips Applied at a per-bit rate (applies to both instruction- and function-tags) 2.3 Instruction Set Abbreviations: EOP: End of program Reg: local register Reg[0] indicates the value at the register specified by an instruction’s first argument (either tag-based or numeric), Reg[1] indicates the value at the register specified by an instruction’s second argument, and Reg[2] indicates the value at the register specified by the instruction’s third argument. Reg[0], Reg[1], etc: Register 0, Register 1, etc. Input: input buffer Follows same scheme as Reg Output: output buffer Follows same scheme as Reg Arg: Instruction argument Arg[i] indicates the i’th instruction argument (an integer encoded in the genome) E.g., Arg[0] is an instruction’s first argument Instructions that would produce undefined behavior (e.g., division by zero) are treated as no operations. 2.3.1 Default Instructions I.e., instructions used across all diagnostic tasks. Instruction Arguments Used Description Nop 0 No operation Not 1 Reg[0] = !Reg[0] Inc 1 Reg[0] = Reg[0] + 1 Dec 1 Reg[0] = Reg[0] - 1 Add 3 Reg[2] = Reg[0] + Reg[1] Sub 3 Reg[2] = Reg[0] - Reg[1] Mult 3 Reg[2] = Reg[0] * Reg[1] Div 3 Reg[2] = Reg[0] / Reg[1] Mod 3 Reg[2] = Reg[0] % Reg[1] TestEqu 3 Reg[2] = Reg[0] == Reg[1] TestNEqu 3 Reg[2] = Reg[0] != Reg[1] TestLess 3 Reg[2] = Reg[0] &lt; Reg[1] TestLessEqu 3 Reg[2] = Reg[0] &lt;= Reg[1] TestGreater 3 Reg[2] = Reg[0] &gt; Reg[1] TestGreaterEqu 3 Reg[2] = Reg[0] &gt;= Reg[1] SetMem 2 Reg[0] = Arg[1] Terminal 1 Reg[0] = double value encoded by instruction tag CopyMem 2 Reg[0] = Reg[1] SwapMem 2 Swap(Reg[0], Reg[1]) InputToWorking 2 Reg[1] = Input[0] WorkingToOutput 2 Output[1] = Reg[0] If 1 If Reg[0] != 0, proceed. Otherwise skip to the next Close or EOP. While 1 While Reg[0] != 0, loop. Otherwise skip to next Close or EOP. Close 0 Indicate the end of a control block of code (e.g., loop, if). Break 0 Break out of current control flow (e.g., loop). Terminate 0 Kill thread that this instruction is executing on. Fork 0 Generate an internal signal (using this instruction’s tag) that can trigger a function to run in parallel. Call 0 Call a function, using this instruction’s tag to determine which function is called. Routine 0 Same as call, but local memory is shared. Sort of like a jump that will jump back when the routine ends. Return 0 Return from the current function call. 2.3.2 Global memory access instructions For experimental conditions without global memory access, these instructions are replaced with no-operation such that the instruction set remains a constant size regardless of experimental condition. Instruction Arguments Used Description WorkingToGlobal 2 Global[1] = Reg[0] GlobalToWorking 2 Reg[1] = Global[0] 2.3.3 Regulation instructions For experimental conditions without regulation, these instructions are replaced with no-operation such that the instruction set remains a constant size regardless of experimental condition. Note that several regulation instructions have a baseline and (-) version. The (-) versions are identical to the baseline version, except that they multiply the value they are regulating with by -1. This eliminates any bias toward either up-/down-regulation. Also note that the emp::MatchBin (in the Empirical library) data structure that manages function regulation is defined in terms of tag DISTANCE, not similarity. So, decreasing function regulation values decreases the distance between potential referring tags, and thus, unintuitively, up-regulates the function. All tag-based referencing used by regulation instructions use unregulated, raw match scores. Thus, programs can still up-regulate a function that was previously ‘turned off’ with down-regulation. Instruction Arguments Used Description SetRegulator 1 Set regulation value of function (targeted with instruction tag) to Reg[0]. SetRegulator- 1 Set regulation value of function (targeted with instruction tag) to -1 * Reg[0]. SetOwnRegulator 1 Set regulation value of function (currently executing) to Reg[0]. SetOwnRegulator- 1 Set regulation value of function (currently executing) to -1 * Reg[0]. AdjRegulator 1 Regulation value of function (targeted with instruction tag) += Reg[0] AdjRegulator- 1 Regulation value of function (targeted with instruction tag) -= Reg[0] AdjOwnRegulator 1 Regulation value of function (currently executing) += Reg[0] AdjOwnRegulator- 1 Regulation value of function (currently executing) -= Reg[0] ClearRegulator 0 Clear function regulation (reset to neutral) of function targeted by instruction’s tag. ClearOwnRegulator 0 Clear function regulation (reset to neutral) of currently executing function SenseRegulator 1 Reg[0] = regulator state of function targeted by instruction tag SenseOwnRegulator 1 Reg[0] = regulator state of current function IncRegulator 0 Increment regulator state of function targeted with this instruction’s tag IncOwnRegulator 0 Increment regulator state of currently executing function DecRegulator 0 Decrement regulator state of function targeted with this instruction’s tag DecOwnRegulator 0 Decrement regulator state of the currently executing function 2.3.4 Task-specific instructions Each task as a number of response instructions added to the instruction set equal to the possible set of responses that can be expressed by a digital organism. Each of these response instructions set a flag on the virtual hardware indicating which response the organism expressed and reset all executing threads such that only function regulation and global memory contents persist. 2.4 References Lalejini, A., &amp; Ofria, C. (2018). Evolving event-driven programs with SignalGP. Proceedings of the Genetic and Evolutionary Computation Conference on - GECCO ’18, 1135–1142. https://doi.org/10.1145/3205455.3205523 Lalejini, A., Wiser, M. J., &amp; Ofria, C. (2017). Gene duplications drive the evolution of complex traits and regulation. Proceedings of the 14th European Conference on Artificial Life ECAL 2017, 257–264. https://doi.org/10.7551/ecal_a_045 "],["changing-signal-problem-analysis.html", "Chapter 3 Changing-signal problem analysis 3.1 Overview 3.2 Analysis Dependencies 3.3 Setup 3.4 Does regulation hinder the evolution of successful genotypes?", " Chapter 3 Changing-signal problem analysis Here, we give an overview of the changing-signal diagnostic problem, and we provide our data analyses for related experiments. All of our source code for statistical analyses and data visualizations is embedded in this document. The raw data can be found on the OSF project associated with this work (link coming). Please file an issue or make a pull request on github to report any mistakes, ask questions, request more explanation, et cetera. 3.1 Overview # Experimental parameters referenced in-text all in one convenient place. time_steps &lt;- 128 replicates &lt;- 200 population_size &lt;- 1000 generations &lt;- 10000 env_complexities &lt;- c(16) # Settings for statistical analyses. alpha &lt;- 0.05 correction_method &lt;- &quot;bonferroni&quot; # Relative location of data. working_directory &lt;- &quot;experiments/2020-11-11-chg-sig/analysis/&quot; # &lt;&lt; For bookdown # working_directory &lt;- &quot;./&quot; # &lt;&lt; For local analysis The changing-signal task requires programs to express a unique response for each of \\(K\\) distinct environmental signals (i.e., each signal has a distinct tag); the figure below is given as an example. Because signals are distinct, programs do not need to alter their responses to particular signals over time. Instead, programs may ‘hardware’ each of the \\(K\\) possible responses to the appropriate environmental signal. However, environmental signals are presented in a random order; thus, the correct order of responses will vary and cannot be hardcoded. As in the repeated signal task, programs respond by executing one of \\(K\\) response instructions. Otherwise, evaluation (and fitness assignment) on the changing-signal task mirrors that of the repeated signal task. Requiring programs to express a distinct instruction in response to each environmental signal represents programs having to perform distinct behaviors. We afforded programs 128 time steps to express the appropriate response after receiving an environmental signal. Once the allotted time to respond expires or the program expresses any response, the program’s threads of execution are reset, resulting in a loss of all thread-local memory. Only the contents of a program’s global memory and each function’s regulatory state persist. The environment then produces the next signal (distinct from all previous signals) to which the program may respond. A program’s fitness is equal to the number of correct responses expressed during evaluation. We evolved populations of 1000 SignalGP programs to solve the changing-signal task at \\(K=16\\) (where \\(K\\) denotes the number of environmental signals). We evolved populations for 10^{4} generations or until an program capable of achieving a perfect score during task evaluation (i.e., able to express the appropriate response to each of the \\(K\\) signals) evolved. We ran 200 replicate populations (each with a distinct random number seed) of each of the following experimental conditions: a regulation-enabled treatment where programs have access to genetic regulation. a regulation-disabled treatment where programs do not have access to genetic regulation. Note this task does not require programs to shift their response to particular signals over time, and as such, genetic regulation is unnecessary. Further, because programs experience environmental inputs in a random order, erroneous genetic regulation can manifest as cryptic variation. For example, non-adaptive down-regulation of a particular response function may be neutral given one sequence of environmental signals, but may be deleterious in another. We expected regulation-enabled SignalGP to exhibit non-adaptive plasticity, potentially resulting in slower adaptation and non-general solutions. 3.2 Analysis Dependencies Load all required R libraries. library(ggplot2) library(tidyverse) library(cowplot) library(viridis) source(&quot;https://gist.githubusercontent.com/benmarwick/2a1bb0133ff568cbe28d/raw/fb53bd97121f7f9ce947837ef1a4c65a73bffb3f/geom_flat_violin.R&quot;) These analyses were conducted in the following computing environment: print(version) ## _ ## platform x86_64-pc-linux-gnu ## arch x86_64 ## os linux-gnu ## system x86_64, linux-gnu ## status ## major 4 ## minor 0.2 ## year 2020 ## month 06 ## day 22 ## svn rev 78730 ## language R ## version.string R version 4.0.2 (2020-06-22) ## nickname Taking Off Again 3.3 Setup Load data, initial data cleanup, configure some global settings. # Load data file data_loc &lt;- paste0(working_directory, &quot;data/max_fit_orgs.csv&quot;) data &lt;- read.csv(data_loc, na.strings=&quot;NONE&quot;) # Define function to summarize regulation/memory configurations. get_con &lt;- function(reg, mem) { if (reg == &quot;0&quot; &amp;&amp; mem == &quot;0&quot;) { return(&quot;none&quot;) } else if (reg == &quot;0&quot; &amp;&amp; mem==&quot;1&quot;) { return(&quot;memory&quot;) } else if (reg==&quot;1&quot; &amp;&amp; mem==&quot;0&quot;) { return(&quot;regulation&quot;) } else if (reg==&quot;1&quot; &amp;&amp; mem==&quot;1&quot;) { return(&quot;both&quot;) } else { return(&quot;UNKNOWN&quot;) } } # Specify experimental condition for each datum. data$condition &lt;- mapply( get_con, data$USE_FUNC_REGULATION, data$USE_GLOBAL_MEMORY ) data$condition &lt;- factor( data$condition, levels=c(&quot;regulation&quot;, &quot;memory&quot;, &quot;none&quot;, &quot;both&quot;) ) # For convenience, create a data set with only solutions # Filter data to include only replicates labeled as solutions sol_data &lt;- filter( data, solution==&quot;1&quot; ) # A lookup table for task complexities task_label_lu &lt;- c( &quot;2&quot; = &quot;2-signal task&quot;, &quot;4&quot; = &quot;4-signal task&quot;, &quot;8&quot; = &quot;8-signal task&quot;, &quot;16&quot; = &quot;16-signal task&quot;, &quot;32&quot; =&quot;32-signal task&quot; ) # Configure our default graphing theme theme_set(theme_cowplot()) 3.4 Does regulation hinder the evolution of successful genotypes? Here, we look at the number of solutions evolved under regulation-enabled and regulation-disabled conditions. A program is categorized as a ‘solution’ if it can correctly respond to each of the \\(K\\) environmental signals during evaluation. # Graph the number of solutions evolved in each condition, faceted by environmental complexity ggplot( sol_data, aes(x=condition, fill=condition) ) + geom_bar() + geom_text( stat=&quot;count&quot;, mapping=aes(label=..count..), position=position_dodge(0.9), vjust=0 ) + scale_x_discrete( name=&quot;Condition&quot;, breaks=c(&quot;memory&quot;,&quot;both&quot;), labels=c(&quot;Regulation-\\ndisabled&quot;,&quot;Regulation-\\nenabled&quot;) ) + ylab(&quot;# successful replciates (/200)&quot;) + theme(legend.position = &quot;none&quot;) + ggtitle(&quot;Successful replicates&quot;) Programs capable of achieving a perfect score on the changing-signal task (for a given sequence of environment signals) evolve in all 200 replicates of each condition (i.e., with and without access to genetic regulation). These programs, however, do not necessarily generalize across all possible sequences of environmental signals. 3.4.1 Does access to regulation slow adaptation? I.e., did successful regulation-enabled programs take longer (more generations) to evolve than those evolved in the regulation-disabled treatment? ggplot( sol_data, aes(x=condition, y=update, fill=condition) ) + geom_flat_violin( position = position_nudge(x = .2, y = 0), alpha = .8 ) + geom_point( aes(y = update, color = condition), position = position_jitter(width = .15), size = .5, alpha = 0.8 ) + geom_boxplot( width = .1, outlier.shape = NA, alpha = 0.5 ) + scale_x_discrete( name=&quot;Condition&quot;, breaks=c(&quot;memory&quot;, &quot;both&quot;), labels=c(&quot;Regulation-\\ndisabled&quot;,&quot;Regulation-\\nenabled&quot;) ) + scale_y_continuous( name=&quot;Generation first solution evolved \\n(log scale)&quot;, ) + guides(fill = FALSE) + guides(color = FALSE) print(wilcox.test(formula=update~condition, data=data, exact=FALSE, conf.int=TRUE)) ## ## Wilcoxon rank sum test with continuity correction ## ## data: update by condition ## W = 22188, p-value = 0.05845 ## alternative hypothesis: true location shift is not equal to 0 ## 95 percent confidence interval: ## -3.860236e-05 1.000000e+01 ## sample estimates: ## difference in location ## 5.000013 The difference in the number of generations before a solution arises is not significantly different. 3.4.2 Do they generalize? Note that solutions may or may not generalize beyond the sequence of environmental signals on which they achieved a perfect score (and were thus categorized as a ‘solution’). We re-evaluated each ‘solution’ on a random sample of 5000 sequences of environmental signals to test for generalization. We deem programs as having successfully generalized only if they responded correctly in all 5000 tests. To see if regulation is preventing some regulation-enabled solutions from generalizing, we test generalization for regulation-enabled solutions with their regulation faculties knocked out (i.e., regulation instructions replaced with no-operations). # Grab count data to make bar plot life easier num_solutions_reg &lt;- length(filter(data, condition==&quot;both&quot; &amp; solution==&quot;1&quot;)$SEED) num_generalize_reg &lt;- length(filter(data, condition==&quot;both&quot; &amp; all_solution==&quot;1&quot;)$SEED) num_generalize_ko_reg &lt;- length(filter(data, condition==&quot;both&quot; &amp; all_solution_ko_reg==&quot;1&quot;)$SEED) num_generalize_mem &lt;- length(filter(data, condition==&quot;memory&quot; &amp; all_solution==&quot;1&quot;)$SEED) sol_cnts &lt;- data.frame(x=1:3) sol_cnts$type &lt;- c(&quot;reg_generalize&quot;, &quot;reg_generalize_ko_reg&quot;, &quot;mem_generalize&quot;) sol_cnts$val &lt;- c(num_generalize_reg, num_generalize_ko_reg, num_generalize_mem) ggplot( sol_cnts, aes(x=type, y=val, fill=type) ) + geom_bar(stat=&quot;identity&quot;) + geom_text( aes(label=val), stat=&quot;identity&quot;, position=position_dodge(0.75), vjust=-0.01 ) + scale_x_discrete( name=&quot;Condition&quot;, limits=c( &quot;mem_generalize&quot;, &quot;reg_generalize&quot;, &quot;reg_generalize_ko_reg&quot; ), labels=c( &quot;Regulation-\\ndisabled&quot;, &quot;Regulation-\\nenabled&quot;, &quot;Regulation-\\nenabled\\n(reg. KO)&quot; ) ) + scale_y_continuous( name=&quot;# of solutions that generalize&quot;, limits=c(0, 210), breaks=seq(0,200,50) ) + theme( legend.position=&quot;none&quot;, axis.text.x = element_text(size=10) ) + ggsave(paste0(working_directory, &quot;imgs/chg-env-16-generalization.png&quot;), width=4,height=4) All regulation-disabled programs successfully generalized. table &lt;- matrix(c(num_generalize_reg, num_generalize_mem, 200 - num_generalize_reg, 200 - num_generalize_mem), nrow=2) rownames(table) &lt;- c(&quot;reg-augmented&quot;, &quot;reg-disabled&quot;) colnames(table) &lt;- c(&quot;success&quot;, &quot;fail&quot;) fisher.test(table) ## ## Fisher&#39;s Exact Test for Count Data ## ## data: table ## p-value = 5.113e-06 ## alternative hypothesis: true odds ratio is not equal to 1 ## 95 percent confidence interval: ## 0.0000000 0.2115509 ## sample estimates: ## odds ratio ## 0 The difference in number of generalizing solutions between regulation-enabled and regulation-disabled conditions is statistically significant (Fisher’s exact test). Moreover, 5 of the 18 non-generalizing programs generalize when we knockout genetic regulation. Upon close inspection, the other 13 non-general programs relied on genetic regulation to achieve initial success but failed to generalize to arbitrary environment signal sequences. "]]
